{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMua2ijg7ILiU7ii3p5+MJy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MihaiDogariu/Keysight-Deep-Learning-Fundamentals/blob/main/Unit%20%232%20-%20Implementing%20a%20perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing a perceptron\n",
        "\n",
        "This notebook makes a brief introduction of the process behind learning a perceptron. We will make it learn some basic mathematical logic functions such as AND, OR, etc."
      ],
      "metadata": {
        "id": "QGxp4xMkJq5-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S84icn-I3bfZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's define our data. We will need all possible combinations of data that the function can cover. Let's start with OR. There are 4 possibilities:\n",
        "- 0 OR 0 => 0\n",
        "- 0 OR 1 => 1\n",
        "- 1 OR 0 => 1\n",
        "- 1 OR 1 => 1\n",
        "\n",
        "The data on the left-hand side of '=>' is the input to the perceptron ($x_1, x_2$), whereas the output/label resides on the right-hand side."
      ],
      "metadata": {
        "id": "K-wqwouVJTAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = np.array([(0, 0), (0, 1), (1, 0), (1, 1)])\n",
        "print(input.shape)\n",
        "labels = np.array([0, 1, 1, 1])\n",
        "print(labels.shape)"
      ],
      "metadata": {
        "id": "TlfDFAD7J_mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let us also build the weights of the perceptron. Since each input is 2-dimensional, we will need 2 weights to accomodate them, and another one to attach to the bias term => a 1 by 3 random vector (use `np.random.rand()`)."
      ],
      "metadata": {
        "id": "HpkyplpuKV-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = np.random.rand(1,3)\n",
        "print(weights.shape)"
      ],
      "metadata": {
        "id": "Biti8cvqKVXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to form the input to the perceptron, we also need to concatenate $x_0=1$ at the start of the input vector, so we will define a function that does exactly that using the [`np.concatenate()`](https://numpy.org/doc/stable/reference/generated/numpy.concatenate.html) function."
      ],
      "metadata": {
        "id": "ZhDG2vJqMIQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def form(x):\n",
        "  return np.concatenate(([1], x))"
      ],
      "metadata": {
        "id": "TaXkdFjL-MT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then, we need to define the activation function, which for a perceptron is a thresholding function, named Heaviside."
      ],
      "metadata": {
        "id": "K2sJi8-YMt9D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def heaviside(x):\n",
        "  if x>=0:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0"
      ],
      "metadata": {
        "id": "DMnvRnF868r-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the forward operation on the network means that we will apply the activation function on the sum ([`np.sum()`](https://numpy.org/doc/stable/reference/generated/numpy.sum.html)) of the product between $x$ and $w$."
      ],
      "metadata": {
        "id": "GC6DhctpM5o2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(x, w):\n",
        "  return heaviside(np.sum(x * w))"
      ],
      "metadata": {
        "id": "Fot5K4lz7JzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to run the weights update algorithm several times. It is impossible to know the exact number of times beforehand so we will run it until there will be no change in the weights variable."
      ],
      "metadata": {
        "id": "zaRmfr4-NPZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs=100\n",
        "lr = 0.1\n",
        "\n",
        "for i in range(num_epochs):\n",
        "  weights_epoch_start = weights\n",
        "  for (in_vec, label) in zip(input, labels):\n",
        "    data = form(in_vec)\n",
        "    output = forward(data, weights)\n",
        "    weights = weights + lr*(label-output)*data\n",
        "  if np.array_equal(weights_epoch_start, weights):\n",
        "    print(\"No change in weights during epoch {}. Ending training.\".format(i))\n",
        "    break"
      ],
      "metadata": {
        "id": "4WyEPVUzOaUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forward([1, 0, 1], weights)"
      ],
      "metadata": {
        "id": "i8GvJv8XWhIQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}